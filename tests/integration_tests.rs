use harness::tools::{CalculatorTool, EchoTool, Tool, ToolRegistry};\nuse model::prelude::*;\nuse serde_json::json;\nuse std::time::Duration;\nuse tokio::time::timeout;\n\n#[tokio::test]\nasync fn test_model_provider_creation() {\n    let config = OllamaConfig::default();\n    let provider = OllamaProvider::new(config);\n    assert!(provider.is_ok());\n    assert_eq!(provider.unwrap().provider_name(), \"ollama\");\n}\n\n#[tokio::test]\nasync fn test_chat_request_building() {\n    let messages = vec![\n        ChatMessage::system(\"You are a helpful assistant\"),\n        ChatMessage::user(\"Hello, world!\"),\n    ];\n\n    let request = ChatRequest::new(\"test-model\", messages)\n        .with_temperature(0.5)\n        .with_max_tokens(100);\n\n    assert_eq!(request.model, \"test-model\");\n    assert_eq!(request.temperature, Some(0.5));\n    assert_eq!(request.max_tokens, Some(100));\n    assert_eq!(request.messages.len(), 2);\n}\n\n#[tokio::test]\nasync fn test_tool_registry() {\n    let mut registry = ToolRegistry::new();\n    registry.register(Box::new(EchoTool::new()));\n    registry.register(Box::new(CalculatorTool::new()));\n\n    assert_eq!(registry.list_tools().len(), 2);\n    assert!(registry.get_tool(\"echo\").is_some());\n    assert!(registry.get_tool(\"calculate\").is_some());\n    assert!(registry.get_tool(\"nonexistent\").is_none());\n\n    let definitions = registry.get_definitions();\n    assert_eq!(definitions.len(), 2);\n\n    let echo_def = definitions.iter().find(|d| d.function.name == \"echo\").unwrap();\n    assert_eq!(echo_def.function.description, \"Echo back the provided message\");\n}\n\n#[tokio::test]\nasync fn test_echo_tool_execution() {\n    let tool = EchoTool::new();\n    let args = json!({ \"message\": \"Hello, World!\" });\n    let result = tool.execute(args).await.unwrap();\n\n    assert_eq!(result[\"echoed\"], \"Hello, World!\");\n    assert!(result[\"timestamp\"].is_string());\n}\n\n#[tokio::test]\nasync fn test_calculator_tool_execution() {\n    let tool = CalculatorTool::new();\n\n    let add_args = json!({\n        \"operation\": \"add\",\n        \"a\": 5.0,\n        \"b\": 3.0\n    });\n    let result = tool.execute(add_args).await.unwrap();\n    assert_eq!(result[\"result\"], 8.0);\n    assert_eq!(result[\"operation\"], \"add\");\n\n    let multiply_args = json!({\n        \"operation\": \"multiply\",\n        \"a\": 4.0,\n        \"b\": 6.0\n    });\n    let result = tool.execute(multiply_args).await.unwrap();\n    assert_eq!(result[\"result\"], 24.0);\n\n    let divide_by_zero_args = json!({\n        \"operation\": \"divide\",\n        \"a\": 10.0,\n        \"b\": 0.0\n    });\n    let result = tool.execute(divide_by_zero_args).await;\n    assert!(result.is_err());\n}\n\n#[tokio::test]\nasync fn test_message_role_serialization() {\n    let message = ChatMessage::user(\"Test message\");\n    let json = serde_json::to_string(&message).unwrap();\n    let deserialized: ChatMessage = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(message.role, deserialized.role);\n    assert_eq!(message.content, deserialized.content);\n}\n\n#[tokio::test]\nasync fn test_tool_choice_serialization() {\n    let choices = vec![\n        ToolChoice::Auto,\n        ToolChoice::None,\n        ToolChoice::Required,\n        ToolChoice::Specific(\"calculate\".to_string()),\n    ];\n\n    for choice in choices {\n        let json = serde_json::to_string(&choice).unwrap();\n        let deserialized: ToolChoice = serde_json::from_str(&json).unwrap();\n        assert!(matches!((choice, deserialized), \n            (ToolChoice::Auto, ToolChoice::Auto) |\n            (ToolChoice::None, ToolChoice::None) |\n            (ToolChoice::Required, ToolChoice::Required) |\n            (ToolChoice::Specific(_), ToolChoice::Specific(_))\n        ));\n    }\n}\n\n#[tokio::test]\nasync fn test_config_validation() {\n    let valid_config = OllamaConfig::default();\n    assert!(valid_config.validate().is_ok());\n\n    let invalid_config = OllamaConfig::new()\n        .with_base_url(\"\")\n        .with_context_length(0)\n        .with_temperature(-1.0);\n    assert!(invalid_config.validate().is_err());\n}\n\n#[tokio::test]\nasync fn test_tool_registry_execution() {\n    let mut registry = ToolRegistry::new();\n    registry.register(Box::new(EchoTool::new()));\n    registry.register(Box::new(CalculatorTool::new()));\n\n    let echo_result = registry\n        .execute(\"echo\", json!({ \"message\": \"test\" }))\n        .await\n        .unwrap();\n    assert_eq!(echo_result[\"echoed\"], \"test\");\n\n    let calc_result = registry\n        .execute(\"calculate\", json!({\n            \"operation\": \"subtract\",\n            \"a\": 10.0,\n            \"b\": 3.0\n        }))\n        .await\n        .unwrap();\n    assert_eq!(calc_result[\"result\"], 7.0);\n\n    let nonexistent_result = registry\n        .execute(\"nonexistent\", json!({}))\n        .await;\n    assert!(nonexistent_result.is_err());\n}\n\n#[tokio::test] \nasync fn test_chat_request_with_tools() {\n    let mut registry = ToolRegistry::new();\n    registry.register(Box::new(EchoTool::new()));\n    registry.register(Box::new(CalculatorTool::new()));\n\n    let tools = registry.get_definitions();\n    let messages = vec![ChatMessage::user(\"Use the echo tool to say hello\")];\n\n    let request = ChatRequest::new(\"test-model\", messages)\n        .with_tools(tools)\n        .with_temperature(0.7);\n\n    assert!(request.tools.is_some());\n    assert_eq!(request.tools.as_ref().unwrap().len(), 2);\n    assert_eq!(request.tool_choice, Some(ToolChoice::Auto));\n}\n\n#[tokio::test]\nasync fn test_model_info_serialization() {\n    let model_info = ModelInfo {\n        name: \"test-model\".to_string(),\n        size: Some(1_000_000_000),\n        digest: Some(\"test-digest\".to_string()),\n        modified_at: Some(\"2024-01-01T00:00:00Z\".to_string()),\n    };\n\n    let json = serde_json::to_string(&model_info).unwrap();\n    let deserialized: ModelInfo = serde_json::from_str(&json).unwrap();\n\n    assert_eq!(model_info.name, deserialized.name);\n    assert_eq!(model_info.size, deserialized.size);\n    assert_eq!(model_info.digest, deserialized.digest);\n    assert_eq!(model_info.modified_at, deserialized.modified_at);\n}\n\n// This test requires Ollama to be running - it's marked as ignored by default\n#[tokio::test]\n#[ignore = \"requires ollama service\"]\nasync fn test_ollama_health_check() {\n    let config = OllamaConfig::default();\n    let provider = OllamaProvider::new(config).unwrap();\n\n    let result = timeout(Duration::from_secs(5), provider.health_check()).await;\n    \n    match result {\n        Ok(Ok(())) => {\n            println!(\"✓ Ollama health check passed\");\n        }\n        Ok(Err(e)) => {\n            println!(\"✗ Ollama health check failed: {}\", e);\n            println!(\"  Make sure Ollama is running on localhost:11434\");\n        }\n        Err(_) => {\n            println!(\"✗ Ollama health check timed out\");\n            println!(\"  Make sure Ollama is running on localhost:11434\");\n        }\n    }\n}\n\n// This test requires Ollama to be running with models - it's marked as ignored by default\n#[tokio::test]\n#[ignore = \"requires ollama service with models\"]\nasync fn test_ollama_list_models() {\n    let config = OllamaConfig::default();\n    let provider = OllamaProvider::new(config).unwrap();\n\n    let result = timeout(Duration::from_secs(5), provider.list_models()).await;\n    \n    match result {\n        Ok(Ok(models)) => {\n            println!(\"✓ Found {} models\", models.len());\n            for model in models {\n                println!(\"  - {}\", model.name);\n            }\n        }\n        Ok(Err(e)) => {\n            println!(\"✗ Failed to list models: {}\", e);\n            println!(\"  Make sure Ollama is running with models installed\");\n        }\n        Err(_) => {\n            println!(\"✗ List models request timed out\");\n        }\n    }\n}"